import pandas as pd import numpy as npimport torch from glob import globimport cv2import osfrom skimage.filters import gaborfrom sklearn.neighbors import KNeighborsClassifierimport skimagefrom sklearn.decomposition import PCAfrom sklearn.metrics import accuracy_score, classification_report ,confusion_matrixTARGET_SIZE=(512,512)def mkdir(path):    try :        os.makedirs(path)    except:        pass    categories_dict =   {'alder': 0,                     'beech': 1,                     'birch': 2,                     'chestnut': 3,                     'ginkgo biloba': 4,                     'hornbeam': 5,                     'horse chestnut': 6,                     'linden': 7,                     'oak': 8,                     'oriental plane': 9,                     'pine': 10,                     'spruce': 11}train_data=glob("./data/Train/**/*.JPG")+glob("./data/Train/**/*.jpg")test_data=glob("./data/test/**/*.JPG")+glob("./data/test/**/*.jpg")     train_data=glob("./data/Train/**/*.JPG")test_data=glob("./data/test/**/*.JPG")train_resnet_path='./resnet_set/Train/'test_resnet_path='./resnet_set/test/'def read_image(img_path):    img = cv2.imread(img_path, 0)    img = cv2.resize(img, TARGET_SIZE)    return(img)def apply_gabor(img):    filt_real, filt_imag = gabor(img, frequency=0.6)    return(filt_real)train_dataset=pd.DataFrame(train_data,columns=["file_name"])train_dataset["label"]=train_dataset["file_name"].apply(lambda x : x.rsplit("/")[-2])train_dataset["name"]=train_dataset["file_name"].apply(lambda x : x.rsplit("/")[-1][:-4])train_dataset["target"]=train_dataset["label"].apply(lambda x :categories_dict[x])train_dataset["image"]=train_dataset["file_name"].apply(lambda x : read_image(x))train_dataset["image"]=train_dataset["image"].apply(lambda x : apply_gabor(x))train_dataset["resnet"]=train_dataset.apply(lambda x : np.load(train_resnet_path+f"{x['label']}_{x['name']}.npy"),axis=1)train_dataset["resnet"]=train_dataset["resnet"].apply(lambda x : np.squeeze(x))test_dataset=pd.DataFrame(test_data,columns=["file_name"])test_dataset["label"]=test_dataset["file_name"].apply(lambda x : x.rsplit("/")[-2])test_dataset["name"]=test_dataset["file_name"].apply(lambda x : x.rsplit("/")[-1][:-4])test_dataset["target"]=test_dataset["label"].apply(lambda x :categories_dict[x])test_dataset["image"]=test_dataset["file_name"].apply(lambda x : read_image(x))test_dataset["image"]=test_dataset["image"].apply(lambda x : apply_gabor(x))test_dataset["resnet"]=test_dataset.apply(lambda x : np.load(test_resnet_path+f"{x['label']}_{x['name']}.npy"),axis=1)test_dataset["resnet"]=test_dataset["resnet"].apply(lambda x : np.squeeze(x))train_dataset=train_dataset.sample(frac=1 , ignore_index=True)test_dataset=test_dataset.sample(frac=1 , ignore_index=True)X_train_resnet=np.vstack(train_dataset["resnet"].values)X_test_resnet=np.vstack(test_dataset["resnet"].values)def feature_extractor(images):    image_dataset = pd.DataFrame()    for image in images:           df = pd.DataFrame()                #greycomatrix(image, distances, angles, levels=256, symmetric=False, normed=False)        #distances - List of pixel pair distance offsets.        #angles - List of pixel pair angles in radians.                #5 configuration for the grey-level co-occurrence matrix calculation        dists = [[1],[3],[5],[3],[3]]        angles = [[0],[0],[0],[np.pi/4],[np.pi/2]]                for n ,(dist, angle) in enumerate(zip(dists, angles)):                    GLCM = skimage.feature.graycomatrix(image, dist, angle)                   GLCM_Energy = skimage.feature.graycoprops(GLCM, 'energy')[0]            df['Energy'+str(n)] = GLCM_Energy            GLCM_corr = skimage.feature.graycoprops(GLCM, 'correlation')[0]            df['Corr'+str(n)] = GLCM_corr                   GLCM_diss = skimage.feature.graycoprops(GLCM, 'dissimilarity')[0]            df['Diss_sim'+str(n)] = GLCM_diss                   GLCM_hom = skimage.feature.graycoprops(GLCM, 'homogeneity')[0]            df['Homogen'+str(n)] = GLCM_hom                   GLCM_contr = skimage.feature.graycoprops(GLCM, 'contrast')[0]            df['Contrast'+str(n)] = GLCM_contr        image_dataset = pd.concat((image_dataset,df))        image_dataset.reset_index(inplace=True, drop=True)        return image_datasettrain_set=feature_extractor(train_dataset["image"])test_set=feature_extractor(test_dataset["image"])x_train=train_set.valuesy_train=train_dataset["target"].valuesx_test=test_set.valuesy_test=test_dataset["target"].valuesX_train=np.hstack((X_train_resnet,x_train))X_test=np.hstack((X_test_resnet,x_test))pca=PCA(100)X_train_pca=pca.fit_transform(X_train)X_test_pca=pca.transform(X_test)knn=KNeighborsClassifier(n_neighbors=5)knn.fit(X_train,y_train)pred=knn.predict(X_test)print(f"accuracy : {accuracy_score(y_test,pred)}")print(f"accuracy : {classification_report(y_test,pred)}")print(confusion_matrix(y_test,pred))